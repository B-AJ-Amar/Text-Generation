{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4619727,"sourceType":"datasetVersion","datasetId":2688897},{"sourceId":6890527,"sourceType":"datasetVersion","datasetId":3942644}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport re \nimport random\nimport string\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score \nfrom sklearn.ensemble import RandomForestClassifier\n\n\nimport tensorflow\nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras.layers import Dense, Input, Dropout, LSTM, Activation\nfrom tensorflow.keras.layers import Embedding\n\n\n!pip install nltk\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk import ngrams\nfrom nltk.probability import FreqDist\n\n# Download necessary NLTK data files\nnltk.download('punkt')\nnltk.download('stopwords')\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-02T19:52:42.112930Z","iopub.execute_input":"2024-08-02T19:52:42.113348Z","iopub.status.idle":"2024-08-02T19:53:12.497907Z","shell.execute_reply.started":"2024-08-02T19:52:42.113316Z","shell.execute_reply":"2024-08-02T19:53:12.496714Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-08-02 19:52:45.457331: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-02 19:52:45.457494: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-02 19:52:45.599782: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk) (1.16.0)\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n/kaggle/input/daigt-proper-train-dataset/train_drcat_03.csv\n/kaggle/input/daigt-proper-train-dataset/train_drcat_02.csv\n/kaggle/input/daigt-proper-train-dataset/train_drcat_04.csv\n/kaggle/input/daigt-proper-train-dataset/train_drcat_01.csv\n/kaggle/input/dailydialog-unlock-the-conversation-potential-in/validation.csv\n/kaggle/input/dailydialog-unlock-the-conversation-potential-in/train.csv\n/kaggle/input/dailydialog-unlock-the-conversation-potential-in/test.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 0. GloVe Embdeing\n---","metadata":{}},{"cell_type":"markdown","source":"### download ...","metadata":{}},{"cell_type":"code","source":"# download stanford GloVe\n!wget http://nlp.stanford.edu/data/glove.6B.zip\n!unzip glove.6B.zip","metadata":{"execution":{"iopub.status.busy":"2024-08-02T19:56:23.488031Z","iopub.execute_input":"2024-08-02T19:56:23.488423Z","iopub.status.idle":"2024-08-02T20:33:47.426418Z","shell.execute_reply.started":"2024-08-02T19:56:23.488389Z","shell.execute_reply":"2024-08-02T20:33:47.425299Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"--2024-08-02 19:56:24--  http://nlp.stanford.edu/data/glove.6B.zip\nResolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\nConnecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://nlp.stanford.edu/data/glove.6B.zip [following]\n--2024-08-02 19:56:24--  https://nlp.stanford.edu/data/glove.6B.zip\nConnecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\nHTTP request sent, awaiting response... 301 Moved Permanently\nLocation: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n--2024-08-02 19:56:24--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\nResolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\nConnecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 862182613 (822M) [application/zip]\nSaving to: 'glove.6B.zip.1'\n\nglove.6B.zip.1      100%[===================>] 822.24M  5.04MB/s    in 2m 39s  \n\n2024-08-02 19:59:04 (5.17 MB/s) - 'glove.6B.zip.1' saved [862182613/862182613]\n\nArchive:  glove.6B.zip\nreplace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n","output_type":"stream"}]},{"cell_type":"code","source":"embedding_dim = 300\ndef load_glove_model(glove_file):\n    print(\"Loading GloVe Model...\")\n    model = {}\n    with open(glove_file, 'r', encoding='utf-8') as f:\n        for line in f:\n            split_line = line.split()\n            word = split_line[0]\n            embedding = np.array([float(val) for val in split_line[1:]])\n            model[word] = embedding\n            \n    model[\"<unk>\"] = np.array([float(0) for _ in range(embedding_dim)] )\n    print(\"Done.\", len(model), \" words loaded!\")\n    return model\n\nglove_model = load_glove_model(f\"glove.6B.{str(embedding_dim)}d.txt\")  \n","metadata":{"execution":{"iopub.status.busy":"2024-08-02T20:34:07.837759Z","iopub.execute_input":"2024-08-02T20:34:07.838438Z","iopub.status.idle":"2024-08-02T20:34:50.703374Z","shell.execute_reply.started":"2024-08-02T20:34:07.838400Z","shell.execute_reply":"2024-08-02T20:34:50.702308Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Loading GloVe Model...\nDone. 400001  words loaded!\n","output_type":"stream"}]},{"cell_type":"code","source":"word_index = list(glove_model.keys())\nvocab_size = len(word_index)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T20:34:50.705761Z","iopub.execute_input":"2024-08-02T20:34:50.706182Z","iopub.status.idle":"2024-08-02T20:34:50.721534Z","shell.execute_reply.started":"2024-08-02T20:34:50.706144Z","shell.execute_reply":"2024-08-02T20:34:50.720284Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### embeding matrix","metadata":{}},{"cell_type":"code","source":"embedding_matrix = np.zeros((vocab_size, embedding_dim))\nfor i in range(len(word_index)):\n    embedding_matrix[i] =  glove_model.get(word_index[i])\n","metadata":{"execution":{"iopub.status.busy":"2024-08-02T20:34:50.722892Z","iopub.execute_input":"2024-08-02T20:34:50.723304Z","iopub.status.idle":"2024-08-02T20:34:52.003197Z","shell.execute_reply.started":"2024-08-02T20:34:50.723269Z","shell.execute_reply":"2024-08-02T20:34:52.002287Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## 1. Data\n---","metadata":{}},{"cell_type":"code","source":"\ndata1 = pd.read_csv(\"/kaggle/input/daigt-proper-train-dataset/train_drcat_01.csv\", usecols =[\"text\"])\ndata2 = pd.read_csv(\"/kaggle/input/daigt-proper-train-dataset/train_drcat_02.csv\", usecols =[\"text\"])\ndata3 = pd.read_csv(\"/kaggle/input/daigt-proper-train-dataset/train_drcat_03.csv\", usecols =[\"text\"])\ndata4 = pd.read_csv(\"/kaggle/input/daigt-proper-train-dataset/train_drcat_04.csv\", usecols =[\"text\"])\n\n\ntrain_data = pd.concat([data1,data2,data3,data4])\n\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-02T20:34:52.006242Z","iopub.execute_input":"2024-08-02T20:34:52.007032Z","iopub.status.idle":"2024-08-02T20:35:00.972347Z","shell.execute_reply.started":"2024-08-02T20:34:52.006993Z","shell.execute_reply":"2024-08-02T20:35:00.970923Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                                text\n0  There are alot reasons to keep our the despise...\n1  Driving smart cars that drive by themself has ...\n2  Dear Principal,\\n\\nI believe that students at ...\n3  Dear Principal,\\n\\nCommunity service should no...\n4  My argument for the development of the driverl...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>There are alot reasons to keep our the despise...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Driving smart cars that drive by themself has ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Dear Principal,\\n\\nI believe that students at ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Dear Principal,\\n\\nCommunity service should no...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>My argument for the development of the driverl...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_data = train_data.dropna()\ndata_size = len(train_data.text)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T20:35:00.973913Z","iopub.execute_input":"2024-08-02T20:35:00.974402Z","iopub.status.idle":"2024-08-02T20:35:01.012430Z","shell.execute_reply.started":"2024-08-02T20:35:00.974360Z","shell.execute_reply":"2024-08-02T20:35:01.011309Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def data_processing(data, word_index=word_index, ngram=4):\n    def preprocess_text(text):\n        text = re.sub(r\"[^A-Za-z0-9\\s]\", \"\", text)\n        tokens = word_tokenize(text.lower())\n        return [word_index.index(token) if token in word_index else word_index.index(\"<unk>\") for token in tokens]\n\n    X, Y = [], []\n    for row in data:\n        sentence = preprocess_text(row)\n        ng = list(ngrams(sentence, ngram))\n        X.extend([gram[:-1] for gram in ng])\n        Y.extend([gram[-1] for gram in ng])\n    return np.array(X), np.array(Y)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T20:35:01.013841Z","iopub.execute_input":"2024-08-02T20:35:01.014149Z","iopub.status.idle":"2024-08-02T20:35:01.023143Z","shell.execute_reply.started":"2024-08-02T20:35:01.014123Z","shell.execute_reply":"2024-08-02T20:35:01.021858Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## 3. Model","metadata":{}},{"cell_type":"code","source":"model = Sequential ([\n    Embedding(input_dim=vocab_size,\n              output_dim=embedding_dim,\n              weights=[embedding_matrix],\n              trainable=False),\n    LSTM(256,return_sequences=True),\n    Dropout(0.2),\n    LSTM(128,return_sequences=False),\n    Dropout(0.2),\n    Dense(200, activation='relu'),\n    Dropout(0.2),\n    Dense(vocab_size, activation='softmax')\n])\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2024-08-02T20:35:01.024332Z","iopub.execute_input":"2024-08-02T20:35:01.024663Z","iopub.status.idle":"2024-08-02T20:35:02.882808Z","shell.execute_reply.started":"2024-08-02T20:35:01.024637Z","shell.execute_reply":"2024-08-02T20:35:02.881872Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### training\n","metadata":{}},{"cell_type":"code","source":"history = []\n\ndef train(epochs =10,sample_size=0.1):\n    global history,data_size\n    if sample_size>data_size-1 :\n        print(\"too large sample size\")\n        return \n    if sample_size>1:\n        r = random.randint(0,data_size-sample_size)\n    elif 0<sample_size <= 1:\n        sample_size = int(sample_size * data_size)\n        print(\"sample_size : \",sample_size)\n        r = random.randint(0,data_size-sample_size)\n    else: \n        print(\"invalid parameters\")\n        return \n        \n    sample_x,sample_y = data_processing(train_data.text[r:r+sample_size])\n    his = model.fit(sample_x,sample_y,epochs = epochs ,validation_split=0.2)\n    \n    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 4))\n\n    ax[0].plot(his.history['accuracy'])\n    ax[0].plot(his.history['val_accuracy'])\n    ax[0].legend(['accuracy', 'val'], loc='upper left')\n\n    ax[1].plot(his.history['loss'])\n    ax[1].plot(his.history['val_loss'])\n    ax[1].legend(['loss', 'val_loss'], loc='upper left')\n\n    plt.show()\n    \n#     history.append(his.history)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T20:35:02.884015Z","iopub.execute_input":"2024-08-02T20:35:02.884347Z","iopub.status.idle":"2024-08-02T20:35:02.894888Z","shell.execute_reply.started":"2024-08-02T20:35:02.884319Z","shell.execute_reply":"2024-08-02T20:35:02.893761Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Verify GPU is available\nprint(\"Num GPUs Available: \", len(tensorflow.config.list_physical_devices('GPU')))","metadata":{"execution":{"iopub.status.busy":"2024-08-02T20:39:06.242323Z","iopub.execute_input":"2024-08-02T20:39:06.243030Z","iopub.status.idle":"2024-08-02T20:39:06.248019Z","shell.execute_reply.started":"2024-08-02T20:39:06.242998Z","shell.execute_reply":"2024-08-02T20:39:06.246959Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Num GPUs Available:  1\n","output_type":"stream"}]},{"cell_type":"code","source":"train(sample_size=0.001)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### prediction","metadata":{}},{"cell_type":"code","source":"\ndef pred(words,lenght=100):\n    word_arr = list(words.split())\n    indexs = [word_index.index(w.lower()) for w in word_arr ]\n    vec = np.array(indexs).reshape(1,3,1)\n    prd = np.argmax(model.predict(vec,verbose=0))\n    prd = word_index[prd] \n    \n    \n    return prd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ncnt = 0\narr = [\"my\",\"name\",'is']\nprint(arr[0],arr[1],end=\" \")\nwhile cnt<100:\n    prd = pred(\" \".join(arr))\n    arr[0] = arr[1]\n    arr[1] = prd\n    cnt +=1\n    print(prd,end=\" \")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Note : \nThis model requires a large amount of data to function as expected. It is intended for learning purposes only.\n","metadata":{}}]}